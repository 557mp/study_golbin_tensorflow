{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# dynamic_rnn 의 sequence_length 옵션\n",
    "# 가변 길이 단어를 학습시킬 수도 있습니다.\n",
    "# 짧은 단어는 긴 단어와 차이만큼을 0 으로 채우고 길이를 계산해 sequence_length 넘겨주면 됩니다. (batch_size 배열로)\n",
    "# 코드가 길어지므로 이해를 위해 이번 예시에서는 단어의 길이를 고정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'there')\n",
      "(1, 'is')\n",
      "(2, 'no')\n",
      "(3, 'cow')\n",
      "(4, 'level')\n",
      "\n",
      " {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
     ]
    }
   ],
   "source": [
    "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# one-hot\n",
    "# {'a':0, 'b':1, 'c':2, 'd':3, 'e':4,  요렇게..   }\n",
    "\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "\n",
    "# enumerate는 \"열거하다\"라는 뜻\n",
    "# 이 함수는 순서가 있는 자료형(리스트, 튜플, 문자열)을 입력으로 받아\n",
    "# 인덱스 값을 포함하는 enumerate 객체를 리턴한다.\n",
    "# (출처: https://wikidocs.net/32)\n",
    "temp_input_data = ['there', 'is', 'no', 'cow', 'level']\n",
    "for num_word in enumerate(temp_input_data):\n",
    "    print(num_word)\n",
    "\n",
    "print('\\n', num_dic)\n",
    "\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
    "\n",
    "# 입력 데이터는 sequential 이고, 앞에 세 글자를 입력(X), 뒤에 한 글자를 출력(Y)으로 사용할 것입니다.\n",
    "# 예) 'love' 라는 단어에 대하여, X는 lov, Y는 e 가 됩니다.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어를 학습에 사용할 수 있는 형태로 변환 <br>\n",
    "1. 입력값, 출력값의 알파벳 인덱스를 구함 <br>\n",
    "2. 입력값을 원핫인코딩으로 변환 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    \n",
    "    for seq in seq_data:\n",
    "        input = [ num_dic[n] for n in seq[:-1] ] # 'wor'  # [22, 14, 17] \n",
    "        target = num_dic[seq[-1]] # 'd' # 3\n",
    "        \n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        # eye(): ones on the diagonal and zeros elsewhere.\n",
    "        # In : np.eye(3)\n",
    "        # Out:\n",
    "        # array([[1., 0., 0.],\n",
    "        #        [0., 1., 0.],\n",
    "        #        [0., 0., 1.]])\n",
    "        \n",
    "        # if input is [0, 1, 2]:\n",
    "        # [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "        #  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "        #  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
    "        \n",
    "        target_batch.append(np.eye(dic_len)[target])\n",
    "\n",
    "    return input_batch, output_batch    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 3, 26), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 10 # 30\n",
    "\n",
    "n_step = 3\n",
    "n_input = n_class = dic_len\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "print(X)\n",
    "Y = tf.placeholder(tf.float32, [None])\n",
    "print(Y) # Y는 원핫이 아니라 그냥 인덱스 숫자를 이용함\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 셀 생성 <br>\n",
    "Dropout 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 신경망 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2]) #순환 신경망\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 출력값 ( RNN -> mnist 형식 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transpose:0\", shape=(3, ?, 128), dtype=float32)\n",
      "Tensor(\"strided_slice:0\", shape=(?, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = tf.transpose(outputs, [1, 0, 2]) # perm = [1,0,2] ?\n",
    "print(outputs)\n",
    "outputs = outputs[-1]\n",
    "print(outputs)\n",
    "model = tf.matmul(outputs, W) + b\n",
    "# 행렬 모양 너무 헷갈린다.. -_-.. 시각적으로 인지하려고 하지말고"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
